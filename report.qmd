---
title: "Predicting Success in March Madness"
subtitle: "Report"
format: html
editor: visual
execute:
  echo: false
---

# **Introduction and Data**

Come March, every college basketball fan is focused on one goal: filling out the perfect March Madness bracket. They are trying to figure out which lower seeded teams are poised to make a surprise run and which higher seeded teams are not as good as advertised. Some have gotten close but still no bracket has been able to correctly predict all 63 games in a tournament.

Even in the 2023 tournament, no websites reported a perfect bracket even after just the first day's slate of games. According to NCAA.com, the chances of a perfect bracket are "1 in 9,223,372,036,854,775,808 (if you just guess or flip a coin) \[or\] 1 in 120.2 billion (if you know a little something about basketball)."

The goal of our project is to answer the question: What factors are the strongest predictors of success in March Madness? We are defining "success" as a team making it into the **Elite Eight** of the tournament. Our hypothesis is that teams with a high BARTHAG value will most be likely to find success in the tournament.

**Data**

The source of the data is from kaggle.com. However, because a lot of the datasets on kaggle.com are fake, we made sure to cross-check the data with official NCAA data on NCAA.com. We found that the dataset contains accurate information. The data from the dataset is pulled from <https://kenpom.com/> and <https://www.barttorvik.com/#>. The data encompasses March Madness tournaments spanning from 2008 - 2023 (2020 not included). Since we downloaded the dataset before the conclusion of the 2023 tournament, we used data from NCAA.com to fill in the missing data for the 2023 March Madness tournament. Each observation in the dataset represents a team in that year's tournament.

**Relevant variables**

Relevant variables were pulled from the dataset by first constructing many boxplots, plotting every single variable in the dataset to round number. We used boxplots as they are pretty clear and effective to show the different numeric distributions for multiple categorical variables. From the boxplots, we roughly estimated which ones seemed to have the highest correlation, and further analyzed them in this report. Below are the three variables we chose to investigate further. They happen to be all from <https://www.barttorvik.com/#>.

BARTHAG: The team's chance of winning against the average DI team

Wins Above Bubble: How many more or less wins the average bubble team would have against the team's schedule

Barttorvik Adjusted Efficiency: Bart Torvik's calculation of how efficient a team is offensively and defensively

# **Literature Review**

In the paper "Using Statistics to Build the Ideal March Madness Bracket" by Sarah Downs, Downs emphasizes the use of different statistical forecasting techniques and looks into factors like team performance measures, player statistics, and historical trends to attempt to build the perfect bracket. Down uses single linear analysis, multiple linear analysis, and polynomial regression in her study and found that the multiple linear analysis performed the best (Downs 2019). Instead of trying to predict a perfect bracket like what Downs attempted, our research intends to predict what teams reach the Elite Eight. We also use different variables in our project. Our research is important since there are so many variables surrounding the March Madness tournament, and it is impossible to analyze every single one in just one study. In our study, we use logistic regression models as well as additive logistic regression models to identify strongest predictors.

# **Methodology**

We first loaded in the necessary packages and our data set.

```{r}
#| label: load-packages

library(tidyverse)
library(tidymodels)

```

```{r}
#| label: read-data

march_madness <- read_csv("data/Tournament_Data.csv")

march_madness_2023 <- read_csv("data/2023_Tournament_Data.csv")

```

We filtered out rounds that equaled 0 or 68 as these represented teams that did not make it into the final 64 team tournament. We also made a new variable called "elite_eight" that stated whether or not a team made it to at least the elite eight. This was our determined measure of success as a team making it to the elite eight had to win 3 games in a row and would essentially end within the top 12.5% of all tournament teams.

```{r}
#| label: clean-data

march_madness <- march_madness |>
  filter(round != 0 & round != 68) |>
  mutate(
    elite_eight = if_else(round <= 8, "elite eight", "not elite eight"),
    elite_eight = as.factor(elite_eight)
  )

march_madness_2023 <- march_madness_2023 |>
  filter(round != 0 & round != 68) |>
  mutate(elite_eight = if_else(round <= 8, "elite eight", "not elite eight"),
         elite_eight = as.factor(elite_eight))
```

Lastly, to set up our data, we split it for training and testing. Training and testing data is important to avoid overfitting.

```{r}
#| label: train-test

set.seed(101) 
march_madness_split <- initial_split(march_madness, prop = 0.80) 
train_data <- training(march_madness_split)
test_data <- testing(march_madness_split) 

```

**Exploratory Plots and Logistic Regression:**

We decided to use logistic regression for our project because we are trying to predict success (making it to the Elite Eight), and our response variable is a categorical variable (elite_eight).

We further make a ROC plot and calculate AUC to help us find the best-fit model of the three variables we investigated and identify which variable is the best predictor of success in the tournament. The following are the three best models that we found from our initial exploratory data analysis.

**BARTHAG model**

```{r}
#| label: model-BARTHAG-boxplot

march_madness |> 
  mutate(round = as.factor(round)) |>
  ggplot(aes(x = round, y = BARTHAG)) +
  geom_boxplot() +
  labs(title = "Relationship between Round and BARTHAG",
         x = "Round",
         y = "BARTHAG") +
  theme_minimal()

```

BARTHAG was one of the best boxplots that we were able to create when plotting each variable to round number (explained more thoroughly in "Relevant variables" above). The median score of BARTHAG increases for the most part for each round that the tournaments advances. The lower quartile especially narrows down and becomes more specific. There are quite a few outliers in the data but that is to be expected given the unpredictability and volatility of events during the NCAA tournament.

```{r}
#| label: model-BARTHAG-log-reg

model_BARTHAG <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ BARTHAG, data = train_data, family = "binomial")

tidy(model_BARTHAG)
```

We created a logistic regression model using BARTHAG to predict whether or not a team will make the elite eight. The equation that models this logistic regression model is:

(where p represents the probability of the team making it to the Elite Eight)

$log(\hat{p} / (1 - \hat{p})) = 20.92 - 21.32*BARTHAG$

$e^{-21.32} = 5.50 * 10^{-10}$, so as BARTHAG increases by 1 unit, the odds ratio is changed by a factor of $5.50 * 10^{-10}$.

```{r}
#| label: model-f-ROC

model_BARTHAG_pred <- predict(model_BARTHAG, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_BARTHAG_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model BARTHAG")
```

We then generated an ROC curve for BARTHAG to see how good the model was in predicting true positives.

```{r}
#| label: model-f-AUC

model_BARTHAG_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 

```

Finally, we calculated the AUC for the BARTHAG model. We got a value of 0.894 for AUC, which is very close to 1, which would have meant that BARTHAG perfectly predicts elite eight teams. This means that BARTHAG is a fairly good predictor of whether or not a team would make it to the elite eight round of March Madness.

**Barttorvik Adjusted Efficiency (BAE) model**

```{r}
#| label: model-BAE-boxplot

march_madness |> 
  mutate(round = as.factor(round)) |> 
  ggplot(aes(x = round, y = b_adj_eff)) +
  geom_boxplot() +
  labs(title = "Relationship between Round and Barttorvik Adjusted Efficiency",
         x = "Round",
         y = "Barttorvik Adjusted Efficiency") +
  theme_minimal()

```

From the boxplot, we can see that the median Barttorvik Adjusted Efficiency generally rises as the event progresses through rounds. As the competition progresses, BAE variability likewise reduces. Again, the data contains a significant number of outliers. However, an overall association can be generally observed: BAE seems to increase as the competition progresses.

We repeat the same process as above--finding the logistic regression equation, making an ROC curve, and calculating AUC.

```{r}
#| label: model-BAE-log-reg

model_BAE <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ b_adj_eff, data = train_data, family = "binomial")

tidy(model_BAE)
```

The equation that models this logistic regression model is:

(where p represents the probability of the team making it to the Elite Eight)

$log(\hat{p} / (1 - \hat{p})) = 6.09 - 0.208 * b\_adj\_eff$

$e^{-0.208} = 0.81$, so as Barttorvik Adjusted Efficiency increases by 1 unit, the odds ratio is changed by a factor of 0.81.

```{r}
#| label: model-BAE-ROC

model_BAE_pred <- predict(model_BAE, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_BAE_pred

model_BAE_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model Barttorvik Adjusted Efficiency")

```

```{r}
#| label: model-BAE-AUC

model_BAE_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 

```

The AUC for the BAE model is 0.891, indicating that BAE is a fairly strong indicator whether or not a team makes it to the elite eight.

**Wins Above Bubble model**

```{r}
#| label: model-WAB-boxplot

march_madness |> 
  mutate(round = as.factor(round)) |> 
  ggplot(aes(x = round, y = wins_above_bubble)) +
  geom_boxplot() +
  labs(title = "Relationship between Round and Wins Above Bubble",
         x = "Round",
         y = "Wins Above Bubble") +
  theme_minimal()

```

From the boxplot, it is observed that the median Wins Above Bubble increases for the most part for each round that the tournaments advances with a few exceptions. As the tournament advance, the variability of WAB also decreases. Again, there are quite a few outliers in the data. However, a general correlation can be roughly seen: as the tournament advances, WAB seems to increase.

```{r}
#| label: model-w-log-reg

model_WAB <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ wins_above_bubble, data = train_data, family = "binomial")

tidy(model_WAB)
```

The equation that models this logistic regression model is:

(where p represents the probability of the team making it to the Elite Eight)

$log(\hat{p} / (1 - \hat{p})) = 3.46 - 0.374 * wins\_above\_bubble$

$e^{-0.374} = 0.69$, so as Wins Above Bubble increases by 1 unit, the odds ratio is changed by a factor of 0.69.

```{r}
#| label: model-WAB-ROC

model_WAB_pred <- predict(model_WAB, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_WAB_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model WAB")
```

```{r}
#| label: model-WAB-AUC

model_WAB_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 
```

The AUC for the Wins Above Bubble model is 0.898. which is the highest value that we got out of the single-variable logistic regression models. This means that WAB is a good predictor of whether or not a team would make it to the elite eight round of March Madness.

**Fitting an Additive Model**

We believe that an additive model is better than interactive because the three stats we are measuring are not related to each other so it does not make sense for them to interact. We will also use forward selection to create our model as there are only three variables we are considering so backwards modeling is not necessary.

**BARTHAG + WAB model**

The first model we will fit and test is using BARTHAG and Wins Above Bubble as those two had the highest AUC when tested individually.

```{r}
#| label: model BARTHAG and WAB


model_BARTHAG_WAB <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ BARTHAG + wins_above_bubble, data = train_data, family = "binomial")

tidy(model_BARTHAG_WAB)

```

The equation that models this logistic regression model is:

(where p represents the probability of the team making it to the Elite Eight)

$log(\hat{p} / (1 - \hat{p})) = 10.07 - 7.93*BARTHAG-0.26*wins\_above\_bubble$

Both variables have a negative coefficient meaning that they both have an odds ratio less than 1 so the odds of a team making it to the Elite Eight for each unit those two variables increase will decrease, holding all else constant. The BARTHAG variable has a larger coefficient meaning it has a greater impact on whether or not a team will make it to the Elite Eight.

```{r}
#| label: model BARTHAG and WAB roc curve


model_BARTHAG_WAB_pred <- predict(model_BARTHAG_WAB, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_BARTHAG_WAB_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model BARTHAG + WAB")
```

```{r}
#| label: model BARTHAG and WAB AUC 

model_BARTHAG_WAB_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 
```

The AUC for this mdoel is 0.902 which means that it is about 1% better than both BARTHAG and wins above bubble at predicting elite eight success individually.

**BARTHAG + BAE model**

Now we test BARTHAG and BAE, our first and third best individual predictors.

```{r}
#| label: model BARTHAG and BAE


model_BARTHAG_BAE <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ BARTHAG + b_adj_eff, data = train_data, family = "binomial")

tidy(model_BARTHAG_BAE)

```

The equation that models this logistic regression model is:

(where p represents the probability of the team making it to the Elite Eight)

$log(\hat{p} / (1 - \hat{p})) = 4.13 + 2.80*BARTHAG-0.23*b\_adj\_eff$

BARTHAG has a positive coefficient in this relationship meaning that, holding all else constant, the odds ratio of a team making it to the Elite Eight increases each time BARTHAG is increased by one unit. However, Bart Torvik Adjusted Efficiency has a negative coefficient meaning that for each unit it increases the odds of a team making the Elite Eight decreases. The BARTHAG variable has a larger coefficient in magnitude meaning it has a greater impact on whether or not a team will make it to the Elite Eight.

```{r}
#| label: model BARTHAG and BAE roc curve and AUC


model_BARTHAG_BAE_pred <- predict(model_BARTHAG_BAE, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_BARTHAG_BAE_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model BARTHAG + BAE")

model_BARTHAG_BAE_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 
```

The AUC for this model is 0.89.

**BAE + WAB model**

Now we will do the BAE and WAB model, our second and third best predictors.

```{r}
#| label: model WAB and BAE


model_WAB_BAE <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ wins_above_bubble + b_adj_eff, data = train_data, family = "binomial")

tidy(model_WAB_BAE)

```

The equation that models this logistic regression model is:

(where p represents the probability of the team making it to the Elite Eight)

$log(\hat{p} / (1 - \hat{p})) = 5.07 - 0.20*wins\_above\_bubble$ $-0.12*b\_adj\_eff$

Both variables have a negative coefficient meaning that they both have an odds ratio less than 1 so the odds of a team making it to the Elite Eight for each unit those two variables increase will decrease, holding all else constant. Both variables have comparably small coefficients so they both don't have a great impact on the success of a team making the Elite Eight.

```{r}
#| label: model WAB and BAE roc curve and AUC


model_WAB_BAE_pred <- predict(model_WAB_BAE, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_WAB_BAE_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model WAB + BAE")

model_WAB_BAE_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 
```

This model has an AUC of 0.901.

**BARTHAG + BAE + WAB model**

Finally we will fit an additive model of all 3 variables.

```{r}
model_BARTHAG_BAE_WAB <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ BARTHAG + wins_above_bubble + b_adj_eff, data = train_data, family = "binomial")

tidy(model_BARTHAG_BAE_WAB)
```

The equation that models this logistic regression is:

(where p represents the probability of the team making it to the Elite Eight)

$log(\hat{p} / (1 - \hat{p})) = 2.86 + 3.15*BARTHAG - 0.20*wins\_above\_bubble$ $- 0.14 * b\_adj\_eff$

BARTHAG again is the only variable that has a positive coefficient meaning that it has a positive effect on the odds of a team making the Elite Eight for each unit that it increases. Wins Above Bubble and Barttorvik Adjusted Efficiency have a negative coefficient so they decrease the odds of a team making the Elite Eight for each unit that they increase. BARTHAG also has by far the greatest magnitude for its coefficient.

```{r}
#| label: model BARTHAG BAE and WAB roc curve


model_BARTHAG_BAE_WAB_pred <- predict(model_BARTHAG_BAE_WAB, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_BARTHAG_BAE_WAB_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model BARTHAG + BAE + WAB")

model_BARTHAG_BAE_WAB_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 
```

We get a AUC value of 0.900, which is actually lower than the previous model that just used BARTHAG and wins above bubble.

**Using our best model to predict for 2023 teams**

```{r}
#| label: testing for 2023 tournament

model_2023 <- predict(model_BARTHAG_WAB, march_madness_2023, type = "prob")|>  
  bind_cols(march_madness_2023 |> select(elite_eight, team))

model_2023 |>
  arrange(desc(`.pred_elite eight`)) |>
  head(8)


```

Our best model predicted that Alabama, Houston, Purdue, UCLA, Kansas, Gonzaga, Texas, and Arizona would be the elite eight teams from the 2023 tournament. This is a success rate of 25% as it got 2/8 teams correct being Texas and Gonzaga. Out of these teams only 5 even made it to the Sweet 16 round. Out of the 8 teams it picked, the model predicted that all four 1 seeds, three 2 seeds, and one 3 seed, showing that it had a heavy bias for teams already rated highly by the people making the bracket. This can be expected as normally these are the teams that have performed the best in the regular season and would likely be more poised to be successful on paper. Our model is far from perfect, which is to be expected given how volatile the NCAA tournament can be.

# **Results**

Our research question was: What factors are the strongest predictors of success in March Madness? In our project, we defined "success" as a team making it into the Elite Eight of the tournament. Our original hypothesis was that teams with a high BARTHAG value would be most likely to find success in the tournament.

From our initial plotting of each variable to the round number, we found the following three variables to seem to be a strong predictor for success in the tournament: 1) BARTHAG, 2) Barttorvik Adjusted Efficiency (or BAE), and 3) Wins Above Bubble (or WAB).

We performed a logistic regression on each variable, with the categorical response variable being whether or not the team made it to the Elite Eight. The equations are provided under "Methodology" as well as the interpretation of the equation coefficients.

ROC (Receiver Operating Characteristic) and AUC (Area Under the ROC Curve) are used to measure how good of a classifier a model is, plotting true and false positive rate, compared to a random classifier. The area under the ROC curve also helps determine how good of a classifier a model is, with AUC = 1.0 being the most ideal model (the higher the AUC the better the model).

Below is a table of all the AUC values we got from our models:

|         | BARTHAG | BAE   | WAB   | BARTHAG + WAB | BARTHAG + BAE | BAE + WAB | BARTHAG + BAE + WAB |
|---------|---------|-------|-------|---------------|---------------|-----------|---------------------|
| **AUC** | 0.894   | 0.891 | 0.898 | 0.903         | 0.890         | 0.901     | 0.900               |

Just comparing AUC values, we found that all of the models, no matter what variables used, performed relatively the same when comparing AUC. However, BARTHAG + WAB is just slightly better. Therefore, we used this model when predicting the results of the 2023 March Madness tournament, in which we were able to correctly predict 2 of the 8 teams that made it to the Elite Eight.

# **Discussion**

Overall, we can conclude that our hypothesis was largely correct as BARTHAG is the only variable in our additive models that have a positive coefficient. This means that it has a positive effect on whether a team makes the elite eight and should be looked into for further testing.

Some of our limitations for our project include our limited number of variables that we investigated. We used a pretty rough method of identifying variables to focus on in our project. Our analysis could be improved by including other variables in our investigation as well as changing the "success" level. In our project, we counted making it to the Elite Eight as a "success," but further analysis could be done to narrow this down to making it to the Final Four or even the National Championship.

Ideas for future work also include investigating other variables, especially individual statistics. The variables we used in our project were mostly composite statistics, meaning that the creator of these stats--in this case, Bart Torvik--had already taken into account many different variables. Individual statistics, such as free throw percentage, could be interesting to investigate. Also, it would be interesting to look into untraditional variables, such as age of the team, previous success, and school funding, and see if any of them could be good predictors of success.

# **Citations**

Downs, Sarah. "Using Statistics to Create the Perfect March Madness Bracket." Journal of Sports Analytics, vol. 5, no. 2, 2019. https://escholarship.org/uc/item/7s99n4nq

https://www.barttorvik.com/#

https://kenpom.com/

https://www.ncaa.com/march-madness-live/scores

https://www.ncaa.com/news/basketball-men/bracketiq/2023-03-16/perfect-ncaa-bracket-absurd-odds-march-madness-dream
