---
title: "Predicting Success in March Madness"
subtitle: "Report"
format: html
editor: visual
execute:
  echo: true
---

# **Introduction and Data**

Come March, every college basketball fan is focused on one goal: filling out the perfect March Madness bracket. They are trying to figure out which lower seeded teams are poised to make a surprise run and which higher seeded teams are not as good as advertised. Some have gotten close but still no bracket has been able to correctly predict all 63 games in a tournament.

In the paper "Using Statistics to Build the Ideal March Madness Bracket" by Sarah Downs, Downs emphasizes the use of different statistical forecasting techniques and looks into factors like team performance measures, player statistics, and historical trends to attempt to build the perfect bracket (Downs 2019).

However, even in the 2023 tournament, no websites reported a perfect bracket even after just the first day's slate of games. We have all tried as well and have failed all the same.

The goal of our project is to answer the question: What factors are the strongest predictors of success in March Madness? We are defining "success" as a team making it into the Elite Eight of the tournament. Our hypothesis is that teams with a high BARTHAG value will most be likely to find success in the tournament.

The source of the data is from kaggle.com. However, because a lot of the datasets on kaggle.com are fake, we made sure to cross-check the data with official NCAA data on NCAA.com. We found that the dataset contains accurate information. The data from the dataset is pulled from <https://kenpom.com/> and <https://www.barttorvik.com/#>. The data encompasses March Madness tournaments spanning from 2008 - 2023 (2020 not included). Since we downloaded the dataset before the conclusion of the 2023 tournament, we used data from NCAA.com to fill in the missing data for the 2023 March Madness tournament. The data wrangling is gone into more detail in the following section. Each observation in the dataset represents a team in that year's tournament.

**Relevant variables**

Relevant variables were pulled from the dataset by first constructing many boxplots, plotting every variable in the dataset to round number. We used boxplots as they are pretty clear and effective to show the different numeric distributions for multiple categorical variables. From the boxplots, we roughly estimated which ones seemed to have the highest correlation, and further analyzed them in this report. Below are the three variables we chose to investigate further. They happen to be all from <https://www.barttorvik.com/#>.

BARTHAG: The team's chance of winning against the average DI team

Wins Above Bubble: How many more or less wins the average bubble team would have against the team's schedule

Barttorvik Adjusted Efficiency: Bart Torvik's calculation of how efficient a team is offensively and defensively

# **Methodology**

Then we loaded in the necessary packages:

```{r}
#| label: load-packages

library(tidyverse)
library(tidymodels)

```

```{r}
#| label: read-data

march_madness <- read_csv("data/Tournament_Data.csv")

march_madness_2023 <- read_csv("data/2023_Tournament_Data.csv")

glimpse(march_madness)
```

We will filter out rounds that equal 0 or 68 as these represent teams that did not make it into the final 64 team tournament. Finally we made a new variable called "elite_eight" that stated whether or not a team made it to at least the elite eight. This was our determined measure of success as a team making it to the elite eight had to win 3 games in a row and would essentially end within the top 12.5% of all tournament teams.

```{r}
#| label: clean-data

march_madness <- march_madness |>
  filter(round != 0 & round != 68) |>
  mutate(
    elite_eight = if_else(round <= 8, "elite eight", "not elite eight"),
    elite_eight = as.factor(elite_eight)
  )

march_madness_2023 <- march_madness_2023 |>
  filter(round != 0 & round != 68) |>
  mutate(elite_eight = if_else(round <= 8, "elite eight", "not elite eight"),
         elite_eight = as.factor(elite_eight))
```

Lastly, to set up our data, we will split it for training and testing. Training and testing data is important to avoid overfitting:

```{r}
#| label: train-test

set.seed(101) 
march_madness_split <- initial_split(march_madness, prop = 0.80) 
train_data <- training(march_madness_split)
test_data <- testing(march_madness_split) 

```

**Exploratory Plots and Logistic Regression**

We decided to use logistic regression for our project because we are trying to predict success (making it to the Elite Eight), and our response variable is a categorical variable (round).

We further calculate AIC, make a ROC plot, and calculate AUC under the ROC plot to help us find the best-fit model of the three variables we investigated and identify which variable is the best predictor of success in the tournament. The following are the three best models that we found from our initial exploratory data analysis.

Model_BARTHAG:

```{r}
#| label: model-f-boxplot

march_madness |> 
  mutate(round = as.factor(round)) |>
  ggplot(aes(x = round, y = BARTHAG)) +
  geom_boxplot() +
  labs(title = "Relationship between Round and BARTHAG",
         x = "Round",
         y = "BARTHAG") +
  theme_minimal()

```

BARTHAG was the best boxplot that I was able to create from the variables that I analyzed. The median score of BARTHAG increases for the most part for each round that the tournaments advances. The lower quartile especially narrows down and becomes more specific. There are quite a few outliers in the data but that is to be expected given the unpredictability and volatility of events during the NCAA tournament.

```{r}
#| label: model-BARTHAG-log-reg

model_BARTHAG <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ BARTHAG, data = train_data, family = "binomial")

tidy(model_BARTHAG)
```

This is the creation of a logistic regression model for using BARTHAG to predict whether or not a team will make the elite eight. The equation that models this logistic regression is: $\widehat{round} = 20.92 - 21.32*BARTHAG$.

```{r}
#| label: model-f-ROC

model_BARTHAG_pred <- predict(model_BARTHAG, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_BARTHAG_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model BARTHAG")
```

In this, we generated an ROC curve for BARTHAG to see how good the model was in predicting true positives. Now, we will calculate the area under the curve (AUC).

```{r}
#| label: model-f-AUC

model_BARTHAG_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 

```

This is the calculation of the AUC for the BARTHAG model. We got a value of 0.894 for AUC, which is very close to 1, which would have meant that BARTHAG perfectly predicts elite eight teams. This means that BARTHAG is a fairly good predictor of whether or not a team would make it to the elite eight round of March Madness.

Model Barttorvik Adjusted Efficiency (BAE):

```{r}
#| label: model-BAE-boxplot

march_madness |> 
  mutate(round = as.factor(round)) |> 
  ggplot(aes(x = round, y = b_adj_eff)) +
  geom_boxplot() +
  labs(title = "Relationship between Round and Barttorvik Adjusted Efficiency",
         x = "Round",
         y = "Barttorvik Adjusted Efficiency") +
  theme_minimal()

```

The median barttorvik adjusted efficiency generally rises as the event progresses through rounds. As the competition progresses, BAE variability likewise reduces. The data contains a significant number of outliers, but this is to be expected given the unpredictable and volatile nature of occurrences throughout the NCAA tournament. However, an overall association can be generally observed: BAE seems to increase as the competition progresses.

```{r}
#| label: model-BAE-log-reg

model_BAE <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ b_adj_eff, data = train_data, family = "binomial")

tidy(model_BAE)
```

$\widehat{round} = 6.09 - 0.208 * b\_adj\_eff$

```{r}
#| label: model-BAE-ROC

model_BAE_pred <- predict(model_BAE, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_BAE_pred

model_BAE_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model Barttorvik Adjusted Efficiency")

```

```{r}
#| label: model-BAE-AUC

model_BAE_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 

```

One of our most significant scores was an AUC of `0.891`, which is the third highest score that we found. This indicates that b_adj_eff is a fairly strong indicator whether or not a team makes it to the elite eight.

Model_WAB (WAB stands for Wins Above Bubble):

```{r}
#| label: model-WAB-boxplot

march_madness |> 
  mutate(round = as.factor(round)) |> 
  ggplot(aes(x = round, y = wins_above_bubble)) +
  geom_boxplot() +
  labs(title = "Relationship between Round and Wins Above Bubble",
         x = "Round",
         y = "Wins Above Bubble") +
  theme_minimal()

```

wins_above_bubble was also one of the best boxplots we were able to create from the variables that we analyzed. The median wins_above_bubble increases for the most part for each round that the tournaments advances with a few exceptions. As the tournament advance, the variability of wins_above_bubble also decreases. There are quite a few outliers in the data but that is to be expected given the unpredictability and volatility of events during the NCAA tournament. However, a general correlation can be roughly seen: as the tournament advances, wins_above_bubble seems to increase.

```{r}
#| label: model-w-log-reg

model_WAB <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ wins_above_bubble, data = train_data, family = "binomial")

tidy(model_WAB)
```

This is the creation of a logistic regression model for using wins_above_bubble to predict whether or not a team will make the elite eight. The equation that models this logistic regression is, p represents the probability of whether or not round equals 1:

$log(\hat{p} / (1 - \hat{p})) = 3.46 - 0.374 * wins\_above\_bubble$

e \^ -0.374 = 0.69, as wins above bubble increases by 1 unit, the odds ratio increases by a factor of 0.69

```{r}
#| label: model-WAB-ROC

model_WAB_pred <- predict(model_WAB, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_WAB_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model WAB")
```

```{r}
#| label: model-w-AUC

model_WAB_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 
```

This is the calculation of the AUC for the wins_above_bubble model. We got a value of 0.898 for AUC, which is the highest scores that we got. This means that wins_above_bubble is a good predictor of whether or not a team would make it to the elite eight round of March Madness.

**Fitting an Additive Model**

We believe that an additive model is better than interactive because the three stats we are measuring are not related to each other so it does not make sense for them to interact. We will also use forward selection to create our model as there are only three variables we are considering so backwards modeling is not necessary.

The first model we will fit and test is using BARTHAG and wins above bubble as those two had the highest AUC when tested individually.

```{r}
#| label: model BARTHAG and WAB


model_BARTHAG_WAB <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ BARTHAG + wins_above_bubble, data = train_data, family = "binomial")

tidy(model_BARTHAG_WAB)

```

Fitted equation: $\widehat{round} = 10.07 - 7.93*BARTHAG-0.26*wins\_above\_bubble$

```{r}
#| label: model BARTHAG and WAB roc curve


model_BARTHAG_WAB_pred <- predict(model_BARTHAG_WAB, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_BARTHAG_WAB_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model BARTHAG + WAB")
```

```{r}
#| label: model BARTHAG and WAB AUC 

model_BARTHAG_WAB_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 
```

The AUC for this mdoel is 0.902 which means that it is about 1% better than both BARTHAG and wins above bubble at predicting elite eight success individually.

Now we test BARTHAG and BAE, our first and third best individual predictors.

```{r}
#| label: model BARTHAG and BAE


model_BARTHAG_BAE <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ BARTHAG + b_adj_eff, data = train_data, family = "binomial")

tidy(model_BARTHAG_BAE)

```

Fitted equation: $\widehat{round} = 4.13 + 2.80*BARTHAG-0.23*b\_adj\_eff$

```{r}
#| label: model BARTHAG and BAE roc curve and AUC


model_BARTHAG_BAE_pred <- predict(model_BARTHAG_BAE, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_BARTHAG_BAE_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model BARTHAG + BAE")

model_BARTHAG_BAE_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 
```

The AUC for this model is 0.89.

Now we will do the BAE and WAB model, our second and third best predictors.

```{r}
#| label: model WAB and BAE


model_WAB_BAE <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ wins_above_bubble + b_adj_eff, data = train_data, family = "binomial")

tidy(model_WAB_BAE)

```

Fitted equation: $\widehat{round} = 5.07 - 0.20*wins\_above\_bubble$ $-0.12*b\_adj\_eff$

```{r}
#| label: model WAB and BAE roc curve and AUC


model_WAB_BAE_pred <- predict(model_WAB_BAE, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_WAB_BAE_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model WAB + BAE")

model_WAB_BAE_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 
```

This model has an AUC of 0.901.

Finally we will fit an additive model of all 3 variables

```{r}
model_BARTHAG_BAE_WAB <- logistic_reg() |>
  set_engine("glm") |>
  fit(elite_eight ~ BARTHAG + wins_above_bubble + b_adj_eff, data = train_data, family = "binomial")

tidy(model_BARTHAG_BAE_WAB)
```

Fitted model: $\widehat{round} = 2.86 + 3.15*BARTHAG - 0.20*wins\_above\_bubble$ $- 0.14 * b\_adj\_eff$

```{r}
#| label: model BARTHAG BAE and WAB roc curve


model_BARTHAG_BAE_WAB_pred <- predict(model_BARTHAG_BAE_WAB, test_data, type = "prob")|>  
  bind_cols(test_data |> select(elite_eight))

model_BARTHAG_BAE_WAB_pred |>
  roc_curve(
    truth = elite_eight,
    `.pred_elite eight`,
    event_level = "first"
  ) |>
  autoplot() +
  labs(title = "ROC curve for model BARTHAG + BAE + WAB")

model_BARTHAG_BAE_WAB_pred |>
  roc_auc(
    truth = elite_eight,
    `.pred_elite eight`, 
    event_level = "first" 
  ) 
```

We get a AUC value of 0.900, which is actually lower than the previous model that just used BARTHAG and wins above bubble.

Using our best model to predict for 2023 teams

```{r}
#| label: testing for 2023 tournament




model_23 <- predict(model_BARTHAG_BAE_WAB, march_madness_2023, type = "prob")|>  
  bind_cols(march_madness_2023 |> select(elite_eight, team))

model_23 |>
  arrange(desc(`.pred_elite eight`))

```

Our best model predicted that Alabama, Houston, Purdue, UCLA, Kansas, Gonzaga, Texas, and Arizona would be the elite eight teams from the 2023 tournament. This is a success rate of 25% as it got 2/8 teams correct being Texas and Gonzaga. Out of these teams only 5 even made it to the Sweet 16 round. Our model is far from perfect, which is to be expected given how volatile the NCAA tournament can be.

**Results**

Our research question was: What factors are the strongest predictors of success in March Madness? In our project, we defined "success" as a team making it into the Elite Eight of the tournament. Our original hypothesis was that teams with a high BARTHAG value would be most likely to find success in the tournament.

From our initial plotting of each variable to the round number, we found the following three variables to seem to be a strong predictor for success in the tournament: 1) BARTHAG (modeled as modelf), 2) Barttorvik adjusted efficiency (modeled as modelm), and 3) wins above bubble (modeled as modelw).

We performed a logistic regression on each variable, with the categorical response variable being round.

AIC, which stands for Akaike information criterion, which is used to compare the fit of models relative to other models. The lower the AIC value the better the model. Below are the three AIC values for the different variables:

BARTHAG: 447.3113

Barttorvik adjusted efficiency: 433.7179

Wins above bubble: 434.0668

Just comparing AIC values, the BARTHAG model had the lowest value, while the Wins Above Bubble Model has just a very slightly higher AIC. The BARTHAG model has the highest AIC value of the three variables. This shows that Barttorvik adjusted efficiency and wins above bubble seem to be the better predictors.

ROC (Receiver Operating Characteristic) and AUC (Area Under the ROC Curve) are used to measure how good of a classifier a model is, plotting true and false positive rate, compared to a random classifier. The area under the ROC curve also helps determine how good of a classifier a model is, with AUC = 1.0 being the most ideal model (the higher the AUC the better the model). Below are the three AUC values for the three different variables.

BARTHAG (modelf): 0.894

Barttorvik adjusted efficiency (modelm): 0.891

Wins above bubble (modelw): 0.898

Just comparing AUC values, it shows that all three variables are pretty good predictors of success. Modelw (Wins above bubble) had the highest value, while modelf (BARTHAG) has just a very slightly lower AUC. Modelm (Barttorvik adjusted efficiency) also has just a slightly lower AUC compared to modelw and modelf. This shows that Wins above bubble seem to be the best predictor, but the other variables also show to be very good predictors.

Back to our research question of identifying the strongest predictors of success in March Madness, we found that the three variables we investigated (BARTHAG, Barttorvik adjusted efficiency, and Wins above bubble) are all great predictors. If we were to identify just one variable as the strongest predictor of success, we would point to Wins above bubble as the strongest predictor since it has the highest AUC value and the second lowest AIC value (just higher than Barttorvik adjusted efficiency by \~0.3489.

However, since we found that all three variables are strong predictors, further research can be done by creating an additive logistic regression pairing up combinations of the three variables to find if an additive logistic regression can produce an even lower AIC and higher AUC value.

# **Citations**

Downs, Sarah. "Using Statistics to Create the Perfect March Madness Bracket." Journal of Sports Analytics, vol. 5, no. 2, 2019. https://escholarship.org/uc/item/7s99n4nq

https://www.barttorvik.com/#

https://kenpom.com/

https://www.ncaa.com/march-madness-live/scores
